{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7954cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-cache-dir transformers==4.5.1 sentencepiece\n",
    "# !pip install -U sentence_transformers\n",
    "# !pip install plotly==4.9.0\n",
    "# !pip install wmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d259190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from scipy.spatial.distance import euclidean, pdist, squareform\n",
    "from sklearn import manifold          #use this for MDS computation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#visualization libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Used to calculation of word movers distance between sentence\n",
    "from collections import Counter\n",
    "\n",
    "#Library to calculate Relaxed-Word Movers distance\n",
    "from wmd import WMD\n",
    "from wmd import libwmdrelax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d4853c",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_path = './output/sentence-transformers_stsb-xlm-r-multilingual-2021-05-11_10-04-26/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b2e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    print('Token embeddings: ', token_embeddings.shape)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    print(sum_embeddings.shape)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def second_last_mean_pooling(model_output, attention_mask):\n",
    "    hidden_layers = model_output[2]\n",
    "    token_embeddings = torch.stack([hidden_layers[1], hidden_layers[-1]]).mean(0)\n",
    "    print('Token embeddings: ', token_embeddings.shape)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    print(sum_embeddings.shape)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def make_attention_mask_without_special_token(attention_mask):\n",
    "    \n",
    "    attention_mask_without_special_tok = attention_mask.clone().detach()\n",
    "    \n",
    "    #set the CLS token index to 0 for all sentences \n",
    "    attention_mask_without_special_tok[:,0] = 0\n",
    "\n",
    "    #get sentence lengths and use that to set those indices to 0 for each length\n",
    "    #essentially, the last index for each sentence, which is the SEP token\n",
    "    sent_len = attention_mask_without_special_tok.sum(1).tolist()\n",
    "\n",
    "    #column indices to set to zero\n",
    "    col_idx = torch.LongTensor(sent_len)\n",
    "    #row indices for all rows\n",
    "    row_idx = torch.arange(attention_mask.size(0)).long()\n",
    "    \n",
    "    #set the SEP indices for each sentence token to zero\n",
    "    attention_mask_without_special_tok[row_idx, col_idx] = 0\n",
    "    return attention_mask_without_special_tok\n",
    "\n",
    "\n",
    "def mean_pooling_no_spec_tokens(model_output, attention_mask):\n",
    "    attention_mask = make_attention_mask_without_special_token(attention_mask)\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def second_last_mean_pooling_no_spec_tokens(model_output, attention_mask):\n",
    "    attention_mask = make_attention_mask_without_special_token(attention_mask)\n",
    "    hidden_layers = model_output[2]\n",
    "    token_embeddings = torch.stack([hidden_layers[1], hidden_layers[-1]]).mean(0)\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e36090bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at ./output/sentence-transformers_stsb-xlm-r-multilingual-2021-05-11_10-04-26/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_path, output_hidden_states=True, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModel.from_pretrained(model_path, config=config)\n",
    "# model.eval()\n",
    "\n",
    "base_config = AutoConfig.from_pretrained('sentence-transformers/stsb-xlm-r-multilingual', output_hidden_states=True, output_attentions=True)\n",
    "base_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/stsb-xlm-r-multilingual', config=base_config)\n",
    "base_model = AutoModel.from_pretrained('sentence-transformers/stsb-xlm-r-multilingual')\n",
    "# base_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dced2e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states', 'attentions'])\n",
      "torch.Size([3, 93, 768])\n"
     ]
    }
   ],
   "source": [
    "#Sentences we want sentence embeddings for\n",
    "# sentences = ['Quiero hincarle el diente a tu culo redondo','Esta noche voy a cogerte bien', 'He amado, he llorado, he besado, me he entregado']\n",
    "sentences = ['Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba',\n",
    "            'Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero',\n",
    "             'He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control']\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, add_special_tokens=True, max_length=128, return_tensors='pt')\n",
    "base_encoded_input = base_tokenizer(sentences, padding=True, truncation=True, max_length=128, add_special_tokens=True, return_tensors='pt')\n",
    "#Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    print(model_output.keys())\n",
    "    print(model_output[2][0].shape)\n",
    "    base_model_output = base_model(**base_encoded_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d30525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embeddings:  torch.Size([3, 93, 768])\n",
      "torch.Size([3, 768])\n",
      "Token embeddings:  torch.Size([3, 93, 768])\n",
      "torch.Size([3, 768])\n",
      "Token embeddings:  torch.Size([3, 93, 768])\n",
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "base_sentence_embeddings = mean_pooling(base_model_output, base_encoded_input['attention_mask'])\n",
    "second_last_sentence_embeddings = second_last_mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2feca0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(sentences, sentence_embeddings):\n",
    "    cosine_scores = util.pytorch_cos_sim(sentence_embeddings, sentence_embeddings)\n",
    "\n",
    "    #Find the pairs with the highest cosine similarity scores\n",
    "    pairs = []\n",
    "    for i in range(len(cosine_scores)-1):\n",
    "        for j in range(i+1, len(cosine_scores)):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "    #Sort scores in decreasing order\n",
    "    pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    for pair in pairs[0:10]:\n",
    "        i, j = pair['index']\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112500ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity - with special tokens\n",
      "Original model\n",
      "Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.6043\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.5667\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t Score: 0.4529\n",
      "Our model\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t Score: 0.7992\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.7797\n",
      "Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.7116\n",
      "taking avarage of second and last layer of our model\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t Score: 0.8653\n",
      "Eso que me atrae de ti no sé lo que es No sé lo que tienes pero quiero que me des Es inevitable, tu figura me llama Luce sana, tu dulce mirada me reclama Quiero conocerte a fondo Contarte las cosas que me ponen cachondo Besarte como un adolescente ardiente Quiero hincarle el diente a tu culo redondo Sexo en la primera mirada Era el postre que se adivinaba \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.8441\n",
      "Esta noche voy a cogerte bien nos iremos a casa de tu papá llamaré a la puerta, nos esconderemos tiraremos piedras para no quedar bien Y cuando piensen quién ha sido le diremos que no, no han sido tus amigos, allí nadie quedó. ya no sabes qué hacer Adiós papá, adiós papá, consíguenos un poco de dinero más (x2) más dinero \t\t He amado, he llorado, he besado, me he entregado He sido mala y hasta cruel Sin pensar en creer en otro hombre en este mundo Pensé que como mujer iba ya a tener bastante No más miedos, no más hombres en mis llantos No más sueños destrozados, no más días sin amar No más sentirme atrapada, vivir sin aire Pero mi plan ha cambiado, he perdido el control \t\t Score: 0.8116\n"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity - with special tokens')\n",
    "print('Original model')\n",
    "cos_sim(sentences, base_sentence_embeddings)\n",
    "print('Our model')\n",
    "cos_sim(sentences, sentence_embeddings)\n",
    "print('taking avarage of second and last layer of our model')\n",
    "cos_sim(sentences, second_last_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b20a5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling_no_spec_tokens(model_output, encoded_input['attention_mask'])\n",
    "base_sentence_embeddings = mean_pooling_no_spec_tokens(base_model_output, base_encoded_input['attention_mask'])\n",
    "second_last_sentence_embeddings = second_last_mean_pooling_no_spec_tokens(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab6b6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity - without special tokens\n",
      "Original model\n",
      "Esta noche voy a cogerte bien \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.3535\n",
      "Quiero hincarle el diente a tu culo redondo \t\t Esta noche voy a cogerte bien \t\t Score: 0.2576\n",
      "Quiero hincarle el diente a tu culo redondo \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.2183\n",
      "Our model\n",
      "Quiero hincarle el diente a tu culo redondo \t\t Esta noche voy a cogerte bien \t\t Score: 0.6919\n",
      "Esta noche voy a cogerte bien \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.4559\n",
      "Quiero hincarle el diente a tu culo redondo \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.4383\n",
      "taking avarage of second and last layer of our model\n",
      "Quiero hincarle el diente a tu culo redondo \t\t Esta noche voy a cogerte bien \t\t Score: 0.6392\n",
      "Quiero hincarle el diente a tu culo redondo \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.4705\n",
      "Esta noche voy a cogerte bien \t\t He amado, he llorado, he besado, me he entregado \t\t Score: 0.4611\n"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity - without special tokens')\n",
    "print('Original model')\n",
    "cos_sim(sentences, base_sentence_embeddings)\n",
    "print('Our model')\n",
    "cos_sim(sentences, sentence_embeddings)\n",
    "print('taking avarage of second and last layer of our model')\n",
    "cos_sim(sentences, second_last_sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbb05c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
